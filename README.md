<<<<<<< HEAD
# Gandhinagari_Algorithms
Intellify â€“ National Level Hackathon 3.0 by Marwadi University (MU), Gujarat

# Sign Language Translator Frontend

<div align="center">

<img width="30.9%" alt="SLT-frontend: Sign Language Translator Frontend logo" src="https://github.com/sign-language-translator/slt-frontend/blob/784d68a419e9c65c88129534b31dfbdd8270d456/public/logo512.png" />


---

## Pages and Features

### 1. Translator

Translate bidirectionally between various text and sign languages using a variety of AI models.

| ![translator](https://github.com/user-attachments/assets/1e1ad62f-6486-422d-b44a-94df315a6195) | ![slt-frontend-demo](https://github.com/user-attachments/assets/a863e8b5-ff42-4a90-b9ee-a0cdb73fdaad) |
| :-: | :-: |
| Design | Current |

### 2. Customize

Annotate sign language datasets and finetune AI models.

#### 2.1 Sign Dictionary Annotation

Label video clips of individual words/signs with text gloss & text translation in various spoken languages and export the data as a mapping JSON.

| ![dictionary](https://github.com/user-attachments/assets/542e9755-6073-413c-98b8-5097ca19a739) | ![label](https://github.com/user-attachments/assets/8a033b45-732d-44bf-8e35-3df99ef24e22)<br/>![sen](https://github.com/user-attachments/assets/749defe5-966d-40e7-9e5d-08e9be707573) |
| :-: | :-: |
| Design | Current |

#### 2.2 Sign Clip Extraction

Specify sections of a long video which correspond to individual sentence, phrase or word, label them with text and export the data as mp4 clips a mapping JSON.

| | ![cllip-extractor](https://github.com/user-attachments/assets/37ffbddf-1711-4555-800f-9d5bdae4aacd) |
| :-: | :-: |
| Design | Current |

#### 2.3 Synthetic Sentences

Arrange sign dictionary videos into sequences and label them with equivalent spoken language texts.

| | ![parallel corpus](https://github.com/user-attachments/assets/e521f09b-6365-45e7-ae22-b5ae1feae809) |
| :-: | :-: |
| Design | Current |

### 3. Learn

Train yourself to use this tool or teach hearing-impaired students quality lessons.

#### 3.1 Walkthrough

Start a step by step walkthrough on which components to click or watch a video tutorial.

#### 3.2 Courses

Interactive lessons in sign language videos, text & audio.

### 4. Documentation

Preview of the python library's documentation & research papers.
=======
# **Sign Language Recognition for Deaf and Dumb**

![Banner](./public/banner.png)

- Our sign language recognition project involved creating a custom dataset, preprocessing images, training a model, integrating with React, and hosting with Firebase. 

- The result is a real-time sign language recognition application that recognizes a variety of sign language gestures.

- Our Model is trained for 26 alphabets and 16 words of ASL and which are commonly used in general communication.

## Features

- Real-Time Recognition

- Easy-to-Use Interface

- Adaptive Learning

- High Accuracy

- Real Time User Progress Data

## Tech Stack

**Front-end:**

- React
- Redux

**Back-end:**

- Firebase (for hosting, authentication, and storage)

**Machine Learning Framework:**

- MediaPipe

**NPM Packages:**

- @mediapipe/drawing_utils
- @mediapipe/hands
- @mediapipe/tasks-vision
- @redux-devtools/extension
- chart.js
- firebase
- js-cookie
- react-chartjs-2
- react-icons
- react-redux
- react-router-dom
- react-toastify
- react-webcam
- redux
- redux-thunk
- uuid

## Team Members

- So this project is a group project done in collaboration with the members mentioned below.

| Name            | Email-id                      |
| :-------------- | :---------------------------- |
| Shubham More    | `shubhamp1251@gmail.com`      |
| Sameer Metkar   | `sameermetkar@gmail.com`      |
| Omkar Mandavkar | `omkarmandavkar000@gmail.com` |
| Durgesh Kolhe   | `dkolhe985@gmail.com`         |

## Project Details

- **Our Project Report:** [Report.pdf](https://drive.google.com/file/d/16juuwsmj64JJ915ghxV7OFlqKyAlTQpB/view?usp=share_link)

- **Published Paper:** [Paper.pdf](https://drive.google.com/file/d/1QAuSWb8op7bFkqhItBbyoqwBbxWbSZvw/view?usp=share_link)

- **Dataset Link:** [Sign_Dataset](https://drive.google.com/drive/folders/1LUUknqqRNHAmIZYrcgo-4n2HrM37uFa3?usp=share_link)

- **Gesture Recogition Documentation:** [Mediapipe](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer)

- **The Model Training File is located in root folder**

## Authors

- [@shubham-more](https://github.com/shubhammore1251/)
- [@sameer-metkar](https://github.com/sameermetkar/)
- [@omkar-mandavkar](https://github.com/omkarmandavkar/)
- [@durgesh-kolhe](https://github.com/Durgesh240)

## Acknowledgements

- [React](https://react.dev/)
- [mediapipe](https://developers.google.com/mediapipe)
- [Firebase](https://firebase.google.com/)
- [NPM](https://www.npmjs.com/)

## Screenshots

![Hello Image](./public/screenshots/Hello.jpg)

![Meet Image](./public/screenshots/Meet.jpg)

![Deaf Image](./public/screenshots/Deaf.jpg)

![Bye Image](./public/screenshots/Bye.jpg)

![D Image](./public/screenshots/D.jpg)

![Dashboard Image](./public/screenshots/dasboard.jpeg)

## Support

For support, contact

- email: shubhamp1251@gmail.com
- LinkedIn: [Shubham More](https://www.linkedin.com/in/shubham-more1251/)
>>>>>>> c103df1 (5th-May-2023 commit)
